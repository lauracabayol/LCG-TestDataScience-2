{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting Started with TEMPERATURE FORECAST","text":"<p>Welcome to the TEMPERATURE FORECAST quick-start guide. This document provides step-by-step instructions for setting up the project, installing necessary dependencies, and initiating model training and prediction using the implemented models.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Prerequisites</li> <li>Installation</li> <li>Usage</li> <li>Deployed model</li> <li>License</li> </ul>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p>Before proceeding, ensure that the following software is installed on your system:</p> <ul> <li>Python 3.10</li> <li>pip</li> <li>Git</li> </ul> <p>You will also need to clone the repository to your local environment by executing the following commands:</p> <pre><code>git clone https://github.com/lauracabayol/TEMPERATURE_FORECAST\ncd TEMPERATURE_FORECAST\n</code></pre>"},{"location":"#installation","title":"Installation","text":""},{"location":"#installation-and-environment-setup","title":"Installation and Environment Setup","text":"<p>We recommend using a virtual environment to install the project dependencies and maintain an isolated workspace.</p>"},{"location":"#setting-up-a-virtual-environment","title":"Setting Up a Virtual Environment:","text":"<p>To create a virtual environment using , run the following commands: <pre><code>python -m venv venv\nsource venv/bin/activate   # On macOS/Linux\n</code></pre>"},{"location":"#2-setting-up-a-conda-environment","title":"2. Setting Up a Conda Environment:","text":"<p>Alternatively, you can create a Conda environment with Python 3.10 by executing the following commands:</p> <pre><code>conda create -n TempForecast -c conda-forge python=3.10\nconda activate TempForecast\n</code></pre> <p>The required python modules are in the  file. <p>Once your environment is ready, proceed with the installation of the package:</p> <pre><code>pip install .\n</code></pre>"},{"location":"#optional-configuring-mlflow","title":"Optional: Configuring MLflow","text":"<p>For advanced users interested in tracking experiments and using MLflow, please follow the official MLflow setup  guide to configure the tracking server.</p>"},{"location":"#usage","title":"Usage","text":""},{"location":"#running-the-models","title":"Running the Models","text":"<p>This project supports two forecasting algorithms:</p> <ul> <li>SARIMA</li> <li>LSTM</li> </ul> <p>Note: The LSTM model is currently deployed for production use.</p>"},{"location":"#training-the-model","title":"Training the Model","text":"<p>To train a model, execute the following command, specifying the algorithm of your choice:</p> <pre><code>python TimeSeriesAnalysis/modeling/train.py --model-type &lt;algorithm name&gt;\n</code></pre> <p>Replace  with one of the following options: <ul> <li>SARIMA</li> <li>LSTM</li> </ul>"},{"location":"#making-predictions","title":"Making Predictions","text":"<p>Once the model has been successfully trained, predictions can be made using the following command:</p> <pre><code>python TimeSeriesAnalysis/modeling/predict.py --model-type 'LSTM'\n</code></pre>"},{"location":"#accessing-the-notebooks","title":"Accessing the notebooks","text":"<p>The notebooks are loaded on GitHub as .py files. To convert them to .ipynb use  <pre><code>jupytext --to ipynb notebooks/*.py\n</code></pre>"},{"location":"#accessing-the-lstm-depolyed-model","title":"Accessing the LSTM depolyed model","text":""},{"location":"#accessing-models-in-mlflow","title":"Accessing Models in MLflow","text":"<p>In the  directory, we use MLflow to access and evaluate multiple models. This allows us to experiment with different model versions and architectures in a flexible manner. Specifically, the notebook loads the models using MLflow's pytorch.load_model function, like this:</p> <pre><code>import mlflow.pytorch\n\n# Define the model name and version\nmodel_name = \"TEMPERATURE_FORECAST\"\nmodel_version = 2\nmodel_uri = f\"models:/{model_name}/{model_version}\"\n\n# Load the model from MLflow\ndeployed_model = mlflow.pytorch.load_model(model_uri)\n</code></pre> <p>This setup allows us to test and compare several models stored in MLflow. However, it requires access to the MLflow registry and tracking server, which is not uploaded to GitHub. Users would need access to our MLflow server to replicate the model loading in this way.</p>"},{"location":"#running-the-best-performing-model-in-a-docker-container","title":"Running the Best-Performing Model in a Docker Container","text":"<p>For convenience, we have created a Docker container that includes the best-performing model along with all necessary dependencies. This allows you to run the model without needing access to MLflow or the associated logs.</p>"},{"location":"#instructions-to-run-the-docker-container","title":"Instructions to Run the Docker Container:","text":"<p>Build the Docker Image: First, clone the repository and navigate to the project directory. Then, build the Docker image:</p> <pre><code>docker build -t temperature-forecasting:latest .\n</code></pre> <p>Run the Docker Container: Once the image is built, run the container using the following command:</p> <pre><code>docker run -p 9999:9999 temperature-forecasting:latest\n</code></pre> <p>This will start a Jupyter notebook where you can interact with the pre-trained best-performing model.</p> <p>Access the Jupyter Notebook: Open your web browser and go to:</p> <pre><code>http://localhost:9999\n</code></pre> <p>The notebook is pre-configured to load and run the best model, so you can use it without needing to access MLflow.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License. You are free to use, modify, and distribute this project as long as you adhere to the license terms.</p>"}]}